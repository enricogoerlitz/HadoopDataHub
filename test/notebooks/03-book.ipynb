{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0X Notebook-Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import pandas as pd\n",
    "import connection as connsettings\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from etl.etl import HadoopStdETL\n",
    "from etl.clients import HiveClient, HDFileSystemClient\n",
    "from etl.datamodels import HostDataClass, TableDataClass\n",
    "from etl.enums import eHdfsFileType\n",
    "from etl.connectors import CsvConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CsvConnector(\n",
       "\t'path=./database/datev.dbo.client.csv',\n",
       "\t'sep=|'\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = CsvConnector(path=\"./database/datev.dbo.client.csv\", sep=\"|\")\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>Omicron Systems GmbH</td>\n",
       "      <td>Musterstraße 57, 10163 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Epic Solutions SE</td>\n",
       "      <td>Musterstraße 19, 10125 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>Quantum Consulting SE</td>\n",
       "      <td>Musterstraße 66, 10172 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   name                        address change_field\n",
       "0  57   Omicron Systems GmbH  Musterstraße 57, 10163 Berlin           cf\n",
       "1  19      Epic Solutions SE  Musterstraße 19, 10125 Berlin           cf\n",
       "2  66  Quantum Consulting SE  Musterstraße 66, 10172 Berlin           cf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Harmony Services GmbH</td>\n",
       "      <td>Musterstraße 30, 10136 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Echo Solutions SE</td>\n",
       "      <td>Musterstraße 17, 10123 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>Mu Enterprises AG</td>\n",
       "      <td>Musterstraße 50, 10156 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   name                        address change_field\n",
       "3  30  Harmony Services GmbH  Musterstraße 30, 10136 Berlin           cf\n",
       "4  17      Echo Solutions SE  Musterstraße 17, 10123 Berlin           cf\n",
       "5  50      Mu Enterprises AG  Musterstraße 50, 10156 Berlin           cf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Momentum Innovations SE</td>\n",
       "      <td>Musterstraße 49, 10155 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92</td>\n",
       "      <td>Xcel Ventures AG</td>\n",
       "      <td>Musterstraße 92, 10198 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     name                        address change_field\n",
       "6  49  Momentum Innovations SE  Musterstraße 49, 10155 Berlin           cf\n",
       "7  92         Xcel Ventures AG  Musterstraße 92, 10198 Berlin           cf\n",
       "8  91   Wavelength Ventures AG  Musterstraße 91, 10197 Berlin           cf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Apex Corporation GmbH</td>\n",
       "      <td>Musterstraße 3, 10109 Berlin</td>\n",
       "      <td>cf uc: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   name                       address change_field\n",
       "9   3  Apex Corporation GmbH  Musterstraße 3, 10109 Berlin     cf uc: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, batch in conn.iterbatches(batchsize=3):\n",
    "    display(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_host = HostDataClass(host=connsettings.HIVE_HOST, port=connsettings.HIVE_PORT)\n",
    "hdfs_host = HostDataClass(host=connsettings.HDFS_HOST, port=connsettings.HDFS_PORT)\n",
    "hdfs_client = HDFileSystemClient(hdfs_host=hdfs_host, hdfs_username=\"enricogoerlitz\")\n",
    "hive_client = HiveClient(host=hive_host, thrift_port=connsettings.HIVE_THRIFT_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/edw/hive/tmp/datev/dbo/client/BATCH0.parquet\n",
      "/edw/hive/tmp/datev/dbo/client/BATCH1.parquet\n",
      "/edw/hive/tmp/datev/dbo/client/BATCH2.parquet\n",
      "/edw/hive/tmp/datev/dbo/client/BATCH3.parquet\n",
      "UPDATE /edw/hive/psa/datev/dbo/client/client\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 23\u001b[0m\n\u001b[1;32m      6\u001b[0m conn \u001b[38;5;241m=\u001b[39m CsvConnector(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./database/datev.dbo.client.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m etl \u001b[38;5;241m=\u001b[39m HadoopStdETL(\n\u001b[1;32m      9\u001b[0m     conn\u001b[38;5;241m=\u001b[39mconn,\n\u001b[1;32m     10\u001b[0m     hdfs_client\u001b[38;5;241m=\u001b[39mhdfs_client,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/test/notebooks/../../etl/etl.py:85\u001b[0m, in \u001b[0;36mHadoopStdETL.start\u001b[0;34m(self, batchsize)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_psa_existing:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# 3.1 Update changed rows and insert deleted rows\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUPDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m, hdfs_dist_path_extended)\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stage_modify_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp impl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/test/notebooks/../../etl/etl.py:174\u001b[0m, in \u001b[0;36mHadoopStdETL._stage_modify_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# pandas or spark? -> pandas!\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# hive read table with LIMIT 2 OFFSET 2;\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# hive_client => read_table_iterbatches(query, batchsize) mit yield?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# 4. write thise data to a batchfile (override = FALSE!)\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hive_host = HostDataClass(host=connsettings.HIVE_HOST, port=connsettings.HIVE_PORT)\n",
    "hdfs_host = HostDataClass(host=connsettings.HDFS_HOST, port=connsettings.HDFS_PORT)\n",
    "hdfs_client = HDFileSystemClient(hdfs_host=hdfs_host, hdfs_username=\"enricogoerlitz\")\n",
    "hive_client = HiveClient(host=hive_host, thrift_port=connsettings.HIVE_THRIFT_PORT)\n",
    "\n",
    "conn = CsvConnector(path=\"./database/datev.dbo.client.csv\", sep=\"|\")\n",
    "\n",
    "etl = HadoopStdETL(\n",
    "    conn=conn,\n",
    "    hdfs_client=hdfs_client,\n",
    "    hive_client=hive_client,\n",
    "    tmp_path=\"/edw/hive/tmp/\",\n",
    "    bck_path=\"/edw/hive/bck_psa/\",\n",
    "    dist_path=\"/edw/hive/psa/\",\n",
    "    table=TableDataClass(\n",
    "        database=\"datev\",\n",
    "        schema=\"dbo\",\n",
    "        table_name=\"client\",\n",
    "        pk=[\"id\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "etl.start(batchsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TableDataClass(table_name='tmp_client', database='datev', schema=None, pk=None),\n",
       " TableDataClass(table_name='client', database='datev', schema=None, pk=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_table = TableDataClass(\"tmp_client\", \"datev\")\n",
    "table = TableDataClass(\"client\", \"datev\")\n",
    "\n",
    "tmp_table, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client.guid</th>\n",
       "      <th>client.pk</th>\n",
       "      <th>client.id</th>\n",
       "      <th>client.name</th>\n",
       "      <th>client.address</th>\n",
       "      <th>client.change_field</th>\n",
       "      <th>client.row_is_current</th>\n",
       "      <th>client.row_valid_from</th>\n",
       "      <th>client.row_valid_to</th>\n",
       "      <th>client.row_filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064bcad7-6974-41c7-97a9-fa8e2405a7f1</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>Omicron Systems GmbH</td>\n",
       "      <td>Musterstraße 57, 10163 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b8e09f28-7762-4c21-8b26-779b4b9a140a</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Epic Solutions SE</td>\n",
       "      <td>Musterstraße 19, 10125 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76f66ef0-76e7-4019-952e-adc98d63b4a4</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>Quantum Consulting SE</td>\n",
       "      <td>Musterstraße 66, 10172 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24fb098f-b139-4186-9375-2c51cd0d1c32</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>Harmony Services GmbH</td>\n",
       "      <td>Musterstraße 30, 10136 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8fff39f0-b6ed-4124-b26c-23501782d585</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Echo Solutions SE</td>\n",
       "      <td>Musterstraße 17, 10123 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            client.guid client.pk  client.id  \\\n",
       "0  064bcad7-6974-41c7-97a9-fa8e2405a7f1        57         57   \n",
       "1  b8e09f28-7762-4c21-8b26-779b4b9a140a        19         19   \n",
       "2  76f66ef0-76e7-4019-952e-adc98d63b4a4        66         66   \n",
       "3  24fb098f-b139-4186-9375-2c51cd0d1c32        30         30   \n",
       "4  8fff39f0-b6ed-4124-b26c-23501782d585        17         17   \n",
       "\n",
       "             client.name                 client.address client.change_field  \\\n",
       "0   Omicron Systems GmbH  Musterstraße 57, 10163 Berlin                  cf   \n",
       "1      Epic Solutions SE  Musterstraße 19, 10125 Berlin                  cf   \n",
       "2  Quantum Consulting SE  Musterstraße 66, 10172 Berlin                  cf   \n",
       "3  Harmony Services GmbH  Musterstraße 30, 10136 Berlin                  cf   \n",
       "4      Echo Solutions SE  Musterstraße 17, 10123 Berlin                  cf   \n",
       "\n",
       "   client.row_is_current client.row_valid_from  client.row_valid_to  \\\n",
       "0                      1   2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "1                      1   2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "2                      1   2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "3                      1   2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "4                      1   2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "\n",
       "                             client.row_filepath  \n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "1  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "2  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "3  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet  \n",
       "4  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive_client.read_table(table).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_client.guid</th>\n",
       "      <th>tmp_client.pk</th>\n",
       "      <th>tmp_client.id</th>\n",
       "      <th>tmp_client.name</th>\n",
       "      <th>tmp_client.address</th>\n",
       "      <th>tmp_client.change_field</th>\n",
       "      <th>tmp_client.row_is_current</th>\n",
       "      <th>tmp_client.row_valid_from</th>\n",
       "      <th>tmp_client.row_valid_to</th>\n",
       "      <th>tmp_client.row_filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6526ad75-eafe-4401-b764-f3f2588aa03d</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>Omicron Systems GmbH</td>\n",
       "      <td>Musterstraße 57, 10163 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ba48bac7-6db3-4e0f-8f56-e27c51363fff</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Epic Solutions SE</td>\n",
       "      <td>Musterstraße 19, 10125 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8e0ba3f3-1269-4d48-981b-c5eb378e60b7</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>Quantum Consulting SE</td>\n",
       "      <td>Musterstraße 66, 10172 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a0a9c40-5579-4aa7-a9d8-36b8c53513cd</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>Harmony Services GmbH</td>\n",
       "      <td>Musterstraße 30, 10136 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9cb7ae45-972c-41d5-973b-5bd58cc10155</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Echo Solutions SE</td>\n",
       "      <td>Musterstraße 17, 10123 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        tmp_client.guid tmp_client.pk  tmp_client.id  \\\n",
       "0  6526ad75-eafe-4401-b764-f3f2588aa03d            57             57   \n",
       "1  ba48bac7-6db3-4e0f-8f56-e27c51363fff            19             19   \n",
       "2  8e0ba3f3-1269-4d48-981b-c5eb378e60b7            66             66   \n",
       "3  0a0a9c40-5579-4aa7-a9d8-36b8c53513cd            30             30   \n",
       "4  9cb7ae45-972c-41d5-973b-5bd58cc10155            17             17   \n",
       "\n",
       "         tmp_client.name             tmp_client.address  \\\n",
       "0   Omicron Systems GmbH  Musterstraße 57, 10163 Berlin   \n",
       "1      Epic Solutions SE  Musterstraße 19, 10125 Berlin   \n",
       "2  Quantum Consulting SE  Musterstraße 66, 10172 Berlin   \n",
       "3  Harmony Services GmbH  Musterstraße 30, 10136 Berlin   \n",
       "4      Echo Solutions SE  Musterstraße 17, 10123 Berlin   \n",
       "\n",
       "  tmp_client.change_field  tmp_client.row_is_current  \\\n",
       "0                      cf                          1   \n",
       "1                      cf                          1   \n",
       "2                      cf                          1   \n",
       "3                      cf                          1   \n",
       "4                      cf                          1   \n",
       "\n",
       "  tmp_client.row_valid_from tmp_client.row_valid_to  \\\n",
       "0       2024-01-03 20:35:28     2262-04-11 23:47:16   \n",
       "1       2024-01-03 20:35:28     2262-04-11 23:47:16   \n",
       "2       2024-01-03 20:35:28     2262-04-11 23:47:16   \n",
       "3       2024-01-03 20:35:28     2262-04-11 23:47:16   \n",
       "4       2024-01-03 20:35:28     2262-04-11 23:47:16   \n",
       "\n",
       "                         tmp_client.row_filepath  \n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "1  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "2  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  \n",
       "3  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet  \n",
       "4  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive_client.read_table(tmp_table).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in hive_client.read_table_iterbatches(tmp_table, batchsize=3):\n",
    "    display(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "24/01/03 20:37:19 WARN Utils: Your hostname, MacBook-Air-von-Enrico.local resolves to a loopback address: 127.0.0.1; using 192.168.0.6 instead (on interface en0)\n",
      "24/01/03 20:37:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/03 20:37:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "|                guid| pk| id|                name|             address|change_field|row_is_current|     row_valid_from|       row_valid_to|        row_filepath|\n",
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "|79e39731-c115-43d...| 49| 49|Momentum Innovati...|Musterstraße 49, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|ffce23f1-0dde-48e...| 92| 92|    Xcel Ventures AG|Musterstraße 92, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|0fab56be-e0f5-464...| 91| 91|Wavelength Ventur...|Musterstraße 91, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|6526ad75-eafe-440...| 57| 57|Omicron Systems GmbH|Musterstraße 57, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|ba48bac7-6db3-4e0...| 19| 19|   Epic Solutions SE|Musterstraße 19, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|8e0ba3f3-1269-4d4...| 66| 66|Quantum Consultin...|Musterstraße 66, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|0a0a9c40-5579-4aa...| 30| 30|Harmony Services ...|Musterstraße 30, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|9cb7ae45-972c-41d...| 17| 17|   Echo Solutions SE|Musterstraße 17, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|8568ed07-4597-411...| 50| 50|   Mu Enterprises AG|Musterstraße 50, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|026f610b-c458-4a6...|  3|  3|Apex Corporation ...|Musterstraße 3, 1...|    cf uc: 1|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "\n",
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "|                guid| pk| id|                name|             address|change_field|row_is_current|     row_valid_from|       row_valid_to|        row_filepath|\n",
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "|903a5c1d-1539-493...| 49| 49|Momentum Innovati...|Musterstraße 49, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|7d059bc0-1dc5-469...| 92| 92|    Xcel Ventures AG|Musterstraße 92, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|aa9d764b-b701-468...| 91| 91|Wavelength Ventur...|Musterstraße 91, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|064bcad7-6974-41c...| 57| 57|Omicron Systems GmbH|Musterstraße 57, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|b8e09f28-7762-4c2...| 19| 19|   Epic Solutions SE|Musterstraße 19, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|76f66ef0-76e7-401...| 66| 66|Quantum Consultin...|Musterstraße 66, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|24fb098f-b139-418...| 30| 30|Harmony Services ...|Musterstraße 30, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|8fff39f0-b6ed-412...| 17| 17|   Echo Solutions SE|Musterstraße 17, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|21fd7381-7622-401...| 50| 50|   Mu Enterprises AG|Musterstraße 50, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|a5fe499a-787a-493...|  3|  3|Apex Corporation ...|Musterstraße 3, 1...|    cf uc: 1|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "+--------------------+---+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = hive_client.create_spark_session()\n",
    "df_tmp_client = spark.sql(f\"SELECT * FROM datev.tmp_client\")\n",
    "df_client = spark.sql(f\"SELECT * FROM datev.client WHERE ROW_IS_CURRENT = 1\")\n",
    "df_tmp_client.show()\n",
    "df_client.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "| pk|                guid| id|                name|             address|change_field|row_is_current|     row_valid_from|       row_valid_to|        row_filepath|                guid| id|                name|             address|change_field|row_is_current|     row_valid_from|       row_valid_to|        row_filepath|\n",
      "+---+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "| 49|79e39731-c115-43d...| 49|Momentum Innovati...|Musterstraße 49, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|903a5c1d-1539-493...| 49|Momentum Innovati...|Musterstraße 49, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 92|ffce23f1-0dde-48e...| 92|    Xcel Ventures AG|Musterstraße 92, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|7d059bc0-1dc5-469...| 92|    Xcel Ventures AG|Musterstraße 92, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 91|0fab56be-e0f5-464...| 91|Wavelength Ventur...|Musterstraße 91, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|aa9d764b-b701-468...| 91|Wavelength Ventur...|Musterstraße 91, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 57|6526ad75-eafe-440...| 57|Omicron Systems GmbH|Musterstraße 57, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|064bcad7-6974-41c...| 57|Omicron Systems GmbH|Musterstraße 57, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 19|ba48bac7-6db3-4e0...| 19|   Epic Solutions SE|Musterstraße 19, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|b8e09f28-7762-4c2...| 19|   Epic Solutions SE|Musterstraße 19, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 66|8e0ba3f3-1269-4d4...| 66|Quantum Consultin...|Musterstraße 66, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|76f66ef0-76e7-401...| 66|Quantum Consultin...|Musterstraße 66, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 30|0a0a9c40-5579-4aa...| 30|Harmony Services ...|Musterstraße 30, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|24fb098f-b139-418...| 30|Harmony Services ...|Musterstraße 30, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 17|9cb7ae45-972c-41d...| 17|   Echo Solutions SE|Musterstraße 17, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|8fff39f0-b6ed-412...| 17|   Echo Solutions SE|Musterstraße 17, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "| 50|8568ed07-4597-411...| 50|   Mu Enterprises AG|Musterstraße 50, ...|          cf|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|21fd7381-7622-401...| 50|   Mu Enterprises AG|Musterstraße 50, ...|          cf|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "|  3|026f610b-c458-4a6...|  3|Apex Corporation ...|Musterstraße 3, 1...|    cf uc: 1|             1|2024-01-03 20:35:28|2262-04-11 23:47:16|/edw/hive/tmp/dat...|a5fe499a-787a-493...|  3|Apex Corporation ...|Musterstraße 3, 1...|    cf uc: 1|             1|2024-01-03 20:35:21|2262-04-11 23:47:16|/edw/hive/tmp/dat...|\n",
      "+---+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+--------------------+---+--------------------+--------------------+------------+--------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmp_client.join(df_client, on=\"pk\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>guid</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>row_is_current</th>\n",
       "      <th>row_valid_from</th>\n",
       "      <th>row_valid_to</th>\n",
       "      <th>row_filepath</th>\n",
       "      <th>CHANGE_KEY</th>\n",
       "      <th>GUID_TMP</th>\n",
       "      <th>CHANGE_KEY_TMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>7d059bc0-1dc5-4698-a4f8-21c22522a82f</td>\n",
       "      <td>92</td>\n",
       "      <td>Xcel Ventures AG</td>\n",
       "      <td>Musterstraße 92, 10198 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH2.parquet</td>\n",
       "      <td>Xcel Ventures AG_cf</td>\n",
       "      <td>ffce23f1-0dde-48e2-b77a-89a79ce5095b</td>\n",
       "      <td>here_name_changed_cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>aa9d764b-b701-4681-bd38-da45fa12ca2c</td>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH2.parquet</td>\n",
       "      <td>Wavelength Ventures AG_cf</td>\n",
       "      <td>0fab56be-e0f5-4646-8813-83a89cb04471</td>\n",
       "      <td>here_name_changed_cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>064bcad7-6974-41c7-97a9-fa8e2405a7f1</td>\n",
       "      <td>57</td>\n",
       "      <td>Omicron Systems GmbH</td>\n",
       "      <td>Musterstraße 57, 10163 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "      <td>Omicron Systems GmbH_cf</td>\n",
       "      <td>6526ad75-eafe-4401-b764-f3f2588aa03d</td>\n",
       "      <td>here_name_changed_cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk                                  guid  id                    name  \\\n",
       "0  92  7d059bc0-1dc5-4698-a4f8-21c22522a82f  92        Xcel Ventures AG   \n",
       "1  91  aa9d764b-b701-4681-bd38-da45fa12ca2c  91  Wavelength Ventures AG   \n",
       "2  57  064bcad7-6974-41c7-97a9-fa8e2405a7f1  57    Omicron Systems GmbH   \n",
       "\n",
       "                         address change_field  row_is_current  \\\n",
       "0  Musterstraße 92, 10198 Berlin           cf               1   \n",
       "1  Musterstraße 91, 10197 Berlin           cf               1   \n",
       "2  Musterstraße 57, 10163 Berlin           cf               1   \n",
       "\n",
       "        row_valid_from         row_valid_to  \\\n",
       "0  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "1  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "2  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "\n",
       "                                    row_filepath                 CHANGE_KEY  \\\n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH2.parquet        Xcel Ventures AG_cf   \n",
       "1  /edw/hive/tmp/datev/dbo/client/BATCH2.parquet  Wavelength Ventures AG_cf   \n",
       "2  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet    Omicron Systems GmbH_cf   \n",
       "\n",
       "                               GUID_TMP        CHANGE_KEY_TMP  \n",
       "0  ffce23f1-0dde-48e2-b77a-89a79ce5095b  here_name_changed_cf  \n",
       "1  0fab56be-e0f5-4646-8813-83a89cb04471  here_name_changed_cf  \n",
       "2  6526ad75-eafe-4401-b764-f3f2588aa03d  here_name_changed_cf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>guid</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>row_is_current</th>\n",
       "      <th>row_valid_from</th>\n",
       "      <th>row_valid_to</th>\n",
       "      <th>row_filepath</th>\n",
       "      <th>CHANGE_KEY</th>\n",
       "      <th>GUID_TMP</th>\n",
       "      <th>CHANGE_KEY_TMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>76f66ef0-76e7-4019-952e-adc98d63b4a4</td>\n",
       "      <td>66</td>\n",
       "      <td>Quantum Consulting SE</td>\n",
       "      <td>Musterstraße 66, 10172 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH0.parquet</td>\n",
       "      <td>Quantum Consulting SE_cf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>24fb098f-b139-4186-9375-2c51cd0d1c32</td>\n",
       "      <td>30</td>\n",
       "      <td>Harmony Services GmbH</td>\n",
       "      <td>Musterstraße 30, 10136 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "      <td>Harmony Services GmbH_cf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>8fff39f0-b6ed-4124-b26c-23501782d585</td>\n",
       "      <td>17</td>\n",
       "      <td>Echo Solutions SE</td>\n",
       "      <td>Musterstraße 17, 10123 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 20:35:21</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH1.parquet</td>\n",
       "      <td>Echo Solutions SE_cf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk                                  guid  id                   name  \\\n",
       "0  66  76f66ef0-76e7-4019-952e-adc98d63b4a4  66  Quantum Consulting SE   \n",
       "1  30  24fb098f-b139-4186-9375-2c51cd0d1c32  30  Harmony Services GmbH   \n",
       "2  17  8fff39f0-b6ed-4124-b26c-23501782d585  17      Echo Solutions SE   \n",
       "\n",
       "                         address change_field  row_is_current  \\\n",
       "0  Musterstraße 66, 10172 Berlin           cf               1   \n",
       "1  Musterstraße 30, 10136 Berlin           cf               1   \n",
       "2  Musterstraße 17, 10123 Berlin           cf               1   \n",
       "\n",
       "        row_valid_from         row_valid_to  \\\n",
       "0  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "1  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "2  2024-01-03 20:35:21  2262-04-11 23:47:16   \n",
       "\n",
       "                                    row_filepath                CHANGE_KEY  \\\n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH0.parquet  Quantum Consulting SE_cf   \n",
       "1  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet  Harmony Services GmbH_cf   \n",
       "2  /edw/hive/tmp/datev/dbo/client/BATCH1.parquet      Echo Solutions SE_cf   \n",
       "\n",
       "  GUID_TMP CHANGE_KEY_TMP  \n",
       "0     None           None  \n",
       "1     None           None  \n",
       "2     None           None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>GUID</th>\n",
       "      <th>PK</th>\n",
       "      <th>ROW_VALID_FROM</th>\n",
       "      <th>ROW_VALID_TO</th>\n",
       "      <th>ROW_IS_CURRENT</th>\n",
       "      <th>ROW_FILEPATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Momentum Innovations SE</td>\n",
       "      <td>Musterstraße 49, 10155 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>79e39731-c115-43d2-9b09-44f09920f689</td>\n",
       "      <td>49</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>1</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH2.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>Xcel Ventures AG</td>\n",
       "      <td>Musterstraße 92, 10198 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>ffce23f1-0dde-48e2-b77a-89a79ce5095b</td>\n",
       "      <td>92</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>1</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH2.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>0fab56be-e0f5-4646-8813-83a89cb04471</td>\n",
       "      <td>91</td>\n",
       "      <td>2024-01-03 20:35:28</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>1</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH2.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     name                        address change_field  \\\n",
       "0  49  Momentum Innovations SE  Musterstraße 49, 10155 Berlin           cf   \n",
       "1  92         Xcel Ventures AG  Musterstraße 92, 10198 Berlin           cf   \n",
       "2  91   Wavelength Ventures AG  Musterstraße 91, 10197 Berlin           cf   \n",
       "\n",
       "                                   GUID  PK       ROW_VALID_FROM  \\\n",
       "0  79e39731-c115-43d2-9b09-44f09920f689  49  2024-01-03 20:35:28   \n",
       "1  ffce23f1-0dde-48e2-b77a-89a79ce5095b  92  2024-01-03 20:35:28   \n",
       "2  0fab56be-e0f5-4646-8813-83a89cb04471  91  2024-01-03 20:35:28   \n",
       "\n",
       "          ROW_VALID_TO  ROW_IS_CURRENT  \\\n",
       "0  2262-04-11 23:47:16               1   \n",
       "1  2262-04-11 23:47:16               1   \n",
       "2  2262-04-11 23:47:16               1   \n",
       "\n",
       "                                    ROW_FILEPATH  \n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH2.parquet  \n",
       "1  /edw/hive/tmp/datev/dbo/client/BATCH2.parquet  \n",
       "2  /edw/hive/tmp/datev/dbo/client/BATCH2.parquet  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "# update dummy\n",
    "df_tmp_client = df_tmp_client.withColumn(\"name\", f.when(f.col(\"pk\") == 91, \"here_name_changed\").otherwise(f.col(\"name\")))\n",
    "df_tmp_client = df_tmp_client.withColumn(\"name\", f.when(f.col(\"pk\") == 92, \"here_name_changed\").otherwise(f.col(\"name\")))\n",
    "df_tmp_client = df_tmp_client.withColumn(\"name\", f.when(f.col(\"pk\") == 57, \"here_name_changed\").otherwise(f.col(\"name\")))\n",
    "\n",
    "# delete dummy\n",
    "df_tmp_client = df_tmp_client.filter(f.col(\"pk\") != 30)\n",
    "df_tmp_client = df_tmp_client.filter(f.col(\"pk\") != 66)\n",
    "df_tmp_client = df_tmp_client.filter(f.col(\"pk\") != 17)\n",
    "\n",
    "df_client = df_client.withColumn(\"CHANGE_KEY\", f.concat_ws(\"_\", *[\"name\", \"change_field\"]))\n",
    "df_tmp_client_ = df_tmp_client.withColumn(\"CHANGE_KEY_TMP\", f.concat_ws(\"_\", *[\"name\", \"change_field\"]))\n",
    "\n",
    "df_tmp_client_ = df_tmp_client_.withColumnRenamed(\"guid\", \"GUID_TMP\")\n",
    "\n",
    "df_tmp_client_ = df_tmp_client_.select(*[\"pk\", \"GUID_TMP\", \"CHANGE_KEY_TMP\"])\n",
    "df_joined = df_client.join(df_tmp_client_, on=\"pk\", how=\"left\")\n",
    "\n",
    "\n",
    "df_updated_rows = df_joined.filter(f.col(\"CHANGE_KEY\") != f.col(\"CHANGE_KEY_TMP\"))\n",
    "df_deleted_rows = df_joined.filter(f.col(\"CHANGE_KEY_TMP\").isNull())\n",
    "\n",
    "#df_tmp_client.show()\n",
    "# df_joined.show()\n",
    "df_updated_rows_pd = pd.DataFrame(\n",
    "    df_updated_rows.collect(),\n",
    "    columns=df_updated_rows.columns\n",
    ")\n",
    "display(df_updated_rows_pd)\n",
    "\n",
    "df_deleted_rows_pd = pd.DataFrame(\n",
    "    df_deleted_rows.collect(),\n",
    "    columns=df_deleted_rows.columns\n",
    ")\n",
    "display(df_deleted_rows_pd)\n",
    "\n",
    "# READ FILE\n",
    "# TRANSFORM IT\n",
    "#   - change and add old dataset ==> need GUID & FILEPATH from old dataset\n",
    "# WRITE IT BACK (override!)\n",
    "# ==> MIT PANDAS!\n",
    "\n",
    "# print(\"CHANGED COLUMNS:\")\n",
    "# df_updated_rows.show()\n",
    "# df_deleted_rows.show()\n",
    "hdfs_client.read_parquet(\"/edw/hive/tmp/datev/dbo/client/BATCH2.parquet\")\n",
    "\n",
    "\n",
    "# UND --> wenn filename doppelt! nur einmal öffnen und verändern!\n",
    "\n",
    "# UPDATE UND DELETE FASSE ICH ABER AUCH NUR EINMAL AN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>guid</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>row_is_current</th>\n",
       "      <th>row_valid_from</th>\n",
       "      <th>row_valid_to</th>\n",
       "      <th>row_filepath</th>\n",
       "      <th>CHANGE_KEY</th>\n",
       "      <th>GUID_TMP</th>\n",
       "      <th>CHANGE_KEY_TMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>b77314dd-59fa-4d73-ae13-97d1339dc000</td>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-03 19:52:19</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH8.parquet</td>\n",
       "      <td>Wavelength Ventures AG_cf</td>\n",
       "      <td>3dd0e68b-6347-45b8-9864-ccc0c6467972</td>\n",
       "      <td>here_name_changed_cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk                                  guid  id                    name  \\\n",
       "0  91  b77314dd-59fa-4d73-ae13-97d1339dc000  91  Wavelength Ventures AG   \n",
       "\n",
       "                         address change_field  row_is_current  \\\n",
       "0  Musterstraße 91, 10197 Berlin           cf               1   \n",
       "\n",
       "        row_valid_from         row_valid_to  \\\n",
       "0  2024-01-03 19:52:19  2262-04-11 23:47:16   \n",
       "\n",
       "                                    row_filepath                 CHANGE_KEY  \\\n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH8.parquet  Wavelength Ventures AG_cf   \n",
       "\n",
       "                               GUID_TMP        CHANGE_KEY_TMP  \n",
       "0  3dd0e68b-6347-45b8-9864-ccc0c6467972  here_name_changed_cf  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated_rows_pd = pd.DataFrame(df_updated_rows.collect(), columns=df_updated_rows.columns)\n",
    "df_updated_rows_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessTime': 0,\n",
       " 'blockSize': 0,\n",
       " 'childrenNum': 1,\n",
       " 'fileId': 40344,\n",
       " 'group': 'supergroup',\n",
       " 'length': 0,\n",
       " 'modificationTime': 1704281132017,\n",
       " 'owner': 'enricogoerlitz',\n",
       " 'pathSuffix': '',\n",
       " 'permission': '755',\n",
       " 'replication': 0,\n",
       " 'storagePolicy': 0,\n",
       " 'type': 'DIRECTORY'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs_client.client.status(\"/edw/hive/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>GUID</th>\n",
       "      <th>PK</th>\n",
       "      <th>ROW_VALID_FROM</th>\n",
       "      <th>ROW_VALID_TO</th>\n",
       "      <th>ROW_IS_CURRENT</th>\n",
       "      <th>ROW_FILEPATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>3dd0e68b-6347-45b8-9864-ccc0c6467972</td>\n",
       "      <td>91</td>\n",
       "      <td>2024-01-03 19:52:25</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>1</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH8.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    name                        address change_field  \\\n",
       "0  91  Wavelength Ventures AG  Musterstraße 91, 10197 Berlin           cf   \n",
       "\n",
       "                                   GUID  PK       ROW_VALID_FROM  \\\n",
       "0  3dd0e68b-6347-45b8-9864-ccc0c6467972  91  2024-01-03 19:52:25   \n",
       "\n",
       "          ROW_VALID_TO  ROW_IS_CURRENT  \\\n",
       "0  2262-04-11 23:47:16               1   \n",
       "\n",
       "                                    ROW_FILEPATH  \n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH8.parquet  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file_path = '/edw/hive/tmp/datev/dbo/client/BATCH8.parquet'\n",
    "\n",
    "hdfs_client.read_parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>change_field</th>\n",
       "      <th>GUID</th>\n",
       "      <th>PK</th>\n",
       "      <th>ROW_VALID_FROM</th>\n",
       "      <th>ROW_VALID_TO</th>\n",
       "      <th>ROW_IS_CURRENT</th>\n",
       "      <th>ROW_FILEPATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Wavelength Ventures AG</td>\n",
       "      <td>Musterstraße 91, 10197 Berlin</td>\n",
       "      <td>cf</td>\n",
       "      <td>3dd0e68b-6347-45b8-9864-ccc0c6467972</td>\n",
       "      <td>91</td>\n",
       "      <td>2024-01-03 19:52:25</td>\n",
       "      <td>2262-04-11 23:47:16</td>\n",
       "      <td>1</td>\n",
       "      <td>/edw/hive/tmp/datev/dbo/client/BATCH8.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    name                        address change_field  \\\n",
       "0  91  Wavelength Ventures AG  Musterstraße 91, 10197 Berlin           cf   \n",
       "\n",
       "                                   GUID  PK       ROW_VALID_FROM  \\\n",
       "0  3dd0e68b-6347-45b8-9864-ccc0c6467972  91  2024-01-03 19:52:25   \n",
       "\n",
       "          ROW_VALID_TO  ROW_IS_CURRENT  \\\n",
       "0  2262-04-11 23:47:16               1   \n",
       "\n",
       "                                    ROW_FILEPATH  \n",
       "0  /edw/hive/tmp/datev/dbo/client/BATCH8.parquet  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "\n",
    "parquet_file_path = '/edw/hive/tmp/datev/dbo/client/BATCH8.parquet'\n",
    "with hdfs_client.client.read(parquet_file_path) as f:\n",
    "    display(pd.read_parquet(BytesIO(f.read())))\n",
    "    # print(f.read())\n",
    "    #print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/1ptjghjd2zd_l124jpvx3sv00000gn/T/ipykernel_7962/179224570.py:13: FutureWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  hdfs = connect(host=hdfs_host, port=hdfs_port, user=hdfs_user)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hadoop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m hdfs_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menricogoerlitz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Path to the Parquet file on HDFS\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create an insecure HDFS connection\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m hdfs \u001b[38;5;241m=\u001b[39m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhdfs_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhdfs_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhdfs_user\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m hdfs\u001b[38;5;241m.\u001b[39mread_parquet(parquet_file_path)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Read the Parquet file into a PyArrow Table\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# table = pq.read_table(hdfs.open_input_file(parquet_file_path))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# # Display the Pandas DataFrame\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(df)\u001b[39;00m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/venv/lib/python3.11/site-packages/pyarrow/hdfs.py:227\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(host, port, user, kerb_ticket, extra_conf)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mDEPRECATED: Connect to an HDFS cluster.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03mfilesystem : HadoopFileSystem\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    224\u001b[0m     _DEPR_MSG\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.HadoopFileSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    226\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkerb_ticket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkerb_ticket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_conf\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/venv/lib/python3.11/site-packages/pyarrow/hdfs.py:237\u001b[0m, in \u001b[0;36m_connect\u001b[0;34m(host, port, user, kerb_ticket, extra_conf)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    236\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[43mHadoopFileSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkerb_ticket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkerb_ticket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mextra_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fs\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/venv/lib/python3.11/site-packages/pyarrow/hdfs.py:47\u001b[0m, in \u001b[0;36mHadoopFileSystem.__init__\u001b[0;34m(self, host, port, user, kerb_ticket, driver, extra_conf)\u001b[0m\n\u001b[1;32m     42\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     43\u001b[0m     _DEPR_MSG\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs.HadoopFileSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.HadoopFileSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibhdfs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[43m_maybe_set_hadoop_classpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(host, port, user, kerb_ticket, extra_conf)\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/venv/lib/python3.11/site-packages/pyarrow/hdfs.py:147\u001b[0m, in \u001b[0;36m_maybe_set_hadoop_classpath\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         classpath \u001b[38;5;241m=\u001b[39m _hadoop_classpath_glob(hadoop_bin)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     classpath \u001b[38;5;241m=\u001b[39m \u001b[43m_hadoop_classpath_glob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhadoop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLASSPATH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m classpath\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataMeshHub/venv/lib/python3.11/site-packages/pyarrow/hdfs.py:172\u001b[0m, in \u001b[0;36m_hadoop_classpath_glob\u001b[0;34m(hadoop_bin)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m    171\u001b[0m hadoop_classpath_args \u001b[38;5;241m=\u001b[39m (hadoop_bin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasspath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--glob\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhadoop_classpath_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hadoop'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyarrow.hdfs import connect\n",
    "\n",
    "# HDFS connection parameters\n",
    "hdfs_host = connsettings.HDFS_HOST\n",
    "hdfs_port = connsettings.HDFS_PORT\n",
    "hdfs_user = 'enricogoerlitz'\n",
    "\n",
    "# Path to the Parquet file on HDFS\n",
    "\n",
    "\n",
    "# Create an insecure HDFS connection\n",
    "hdfs = connect(host=hdfs_host, port=hdfs_port, user=hdfs_user)\n",
    "hdfs.read_parquet(parquet_file_path)\n",
    "# Read the Parquet file into a PyArrow Table\n",
    "# table = pq.read_table(hdfs.open_input_file(parquet_file_path))\n",
    "\n",
    "# # Convert the PyArrow Table to a Pandas DataFrame\n",
    "# df = table.to_pandas()\n",
    "\n",
    "# # Display the Pandas DataFrame\n",
    "# print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
