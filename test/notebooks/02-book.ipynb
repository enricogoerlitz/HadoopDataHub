{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0X Notebook-Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import pandas as pd\n",
    "import connection as conn\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from etl.clients import HiveClient\n",
    "from etl.datamodels import HostDataClass, TableDataClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_host = HostDataClass(host=conn.HIVE_HOST, port=conn.HIVE_PORT)\n",
    "hdfs_host = HostDataClass(host=conn.HDFS_HOST, port=conn.HDFS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive = HiveClient(host=hive_host, thrift_port=conn.HIVE_THRIFT_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive retrieve data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDataClass(table_name='employee_pay_test', database='default', schema=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_employee_pay_test = TableDataClass(\n",
    "    database=\"default\",\n",
    "    table_name=\"employee_pay_test\"\n",
    ")\n",
    "tbl_employee_pay_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default', 'psa']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive.get_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigdata',\n",
       " 'employee_pay_test',\n",
       " 'firstviewonhive',\n",
       " 'hiveexternaltable',\n",
       " 'hiveexternaltable_parquet',\n",
       " 'my_table',\n",
       " 'my_table_test1113',\n",
       " 'new_table',\n",
       " 'new_table_2',\n",
       " 'parquetfile',\n",
       " 'parquetfile2']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['dbo_table', 'hiveexternaltableview', 'newtable']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    hive.get_tables(),\n",
    "    hive.get_tables(database=\"psa\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employee_id</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>client_id</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>costcenter_id</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paytype_id</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amount</td>\n",
       "      <td>double</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col_name data_type comment\n",
       "0  transaction_date    string        \n",
       "1       employee_id    bigint        \n",
       "2         client_id    bigint        \n",
       "3     costcenter_id    bigint        \n",
       "4        paytype_id    bigint        \n",
       "5            amount    double        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive.describe_table(\n",
    "    table=tbl_employee_pay_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_pay_test.transaction_date</th>\n",
       "      <th>employee_pay_test.employee_id</th>\n",
       "      <th>employee_pay_test.client_id</th>\n",
       "      <th>employee_pay_test.costcenter_id</th>\n",
       "      <th>employee_pay_test.paytype_id</th>\n",
       "      <th>employee_pay_test.amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5298.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>927.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>794.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>662.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>529.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>397.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>264.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>3800</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>132.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2091</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4795.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2091</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>839.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_pay_test.transaction_date  employee_pay_test.employee_id  \\\n",
       "0                         2000-01-31                           3800   \n",
       "1                         2000-01-31                           3800   \n",
       "2                         2000-01-31                           3800   \n",
       "3                         2000-01-31                           3800   \n",
       "4                         2000-01-31                           3800   \n",
       "5                         2000-01-31                           3800   \n",
       "6                         2000-01-31                           3800   \n",
       "7                         2000-01-31                           3800   \n",
       "8                         2000-01-31                           2091   \n",
       "9                         2000-01-31                           2091   \n",
       "\n",
       "   employee_pay_test.client_id  employee_pay_test.costcenter_id  \\\n",
       "0                           50                               17   \n",
       "1                           50                               17   \n",
       "2                           50                               17   \n",
       "3                           50                               17   \n",
       "4                           50                               17   \n",
       "5                           50                               17   \n",
       "6                           50                               17   \n",
       "7                           50                               17   \n",
       "8                           83                                2   \n",
       "9                           83                                2   \n",
       "\n",
       "   employee_pay_test.paytype_id  employee_pay_test.amount  \n",
       "0                             1                   5298.23  \n",
       "1                             2                    927.19  \n",
       "2                             3                    794.73  \n",
       "3                             4                    662.28  \n",
       "4                             5                    529.82  \n",
       "5                             6                    397.37  \n",
       "6                             7                    264.91  \n",
       "7                             8                    132.46  \n",
       "8                             1                   4795.34  \n",
       "9                             2                    839.18  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive.read_table(tbl_employee_pay_test, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3800</td>\n",
       "      <td>5298.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>927.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3800</td>\n",
       "      <td>794.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3800</td>\n",
       "      <td>662.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3800</td>\n",
       "      <td>529.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3800</td>\n",
       "      <td>397.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3800</td>\n",
       "      <td>264.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3800</td>\n",
       "      <td>132.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2091</td>\n",
       "      <td>4795.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2091</td>\n",
       "      <td>839.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2091</td>\n",
       "      <td>719.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2091</td>\n",
       "      <td>599.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2091</td>\n",
       "      <td>479.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2091</td>\n",
       "      <td>359.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2091</td>\n",
       "      <td>239.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id   amount\n",
       "0          3800  5298.23\n",
       "1          3800   927.19\n",
       "2          3800   794.73\n",
       "3          3800   662.28\n",
       "4          3800   529.82\n",
       "5          3800   397.37\n",
       "6          3800   264.91\n",
       "7          3800   132.46\n",
       "8          2091  4795.34\n",
       "9          2091   839.18\n",
       "10         2091   719.30\n",
       "11         2091   599.42\n",
       "12         2091   479.53\n",
       "13         2091   359.65\n",
       "14         2091   239.77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hive.read_table(\n",
    "    table=tbl_employee_pay_test,\n",
    "    columns=[\"employee_id\", \"amount\"],\n",
    "    limit=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTERNAL TABLE IF NOT EXISTS your_table_name (\n",
      "    `col-int` BIGINT, `col-float` DOUBLE, `col-string` STRING, `col-bool` BOOLEAN, `col-datetime` TIMESTAMP\n",
      ")\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ','\n",
      "STORED AS TEXTFILE\n",
      "LOCATION '/your/hdfs/location'\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'col-int': pd.Series([1, 2, 3, 4, 5], dtype=int),\n",
    "    'col-float': pd.Series([1.1, 2.2, 3.3, 4.4, 5.5], dtype=float),\n",
    "    'col-string': pd.Series(['a', 'b', 'c', 'd', 'e'], dtype=str),\n",
    "    'col-bool': pd.Series([True, False, True, False, True], dtype=bool),\n",
    "    'col-datetime': pd.to_datetime(['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01']),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def generate_hive_table_statement(df, table_name, hdfs_location):\n",
    "    columns = []\n",
    "    \n",
    "    for column_name, dtype in df.dtypes.items():\n",
    "        # Ignoriere die 'Category'-Spalte\n",
    "        if dtype.name != 'category':\n",
    "            # Mappe Pandas-Datentypen zu HiveQL-Datentypen\n",
    "            hive_dtype = 'BIGINT' if dtype == 'int64' else \\\n",
    "                         'DOUBLE' if dtype == 'float64' else \\\n",
    "                         'STRING' if dtype == 'object' else \\\n",
    "                         'BOOLEAN' if dtype == 'bool' else \\\n",
    "                         'TIMESTAMP' if dtype.name == 'datetime64[ns]' else None\n",
    "\n",
    "            if hive_dtype:\n",
    "                columns.append(f\"`{column_name}` {hive_dtype}\")\n",
    "\n",
    "    # Erstelle das CREATE EXTERNAL TABLE Statement\n",
    "    hiveql_statement = (\n",
    "        f\"CREATE EXTERNAL TABLE IF NOT EXISTS {table_name} (\\n\"\n",
    "        f\"    {', '.join(columns)}\\n\"\n",
    "        \")\\n\"\n",
    "        \"ROW FORMAT DELIMITED\\n\"\n",
    "        \"FIELDS TERMINATED BY ','\\n\"\n",
    "        f\"STORED AS TEXTFILE\\n\"\n",
    "        f\"LOCATION '{hdfs_location}'\"\n",
    "    )\n",
    "\n",
    "    return hiveql_statement\n",
    "\n",
    "# Verwendung der Funktion\n",
    "table_name = 'your_table_name'\n",
    "hdfs_location = '/your/hdfs/location'\n",
    "hiveql_statement = generate_hive_table_statement(df, table_name, hdfs_location)\n",
    "\n",
    "print(hiveql_statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "No result set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_hive_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhiveql_statement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/test/notebooks/../../etl/clients.py:129\u001b[0m, in \u001b[0;36mHiveClient.execute_hive_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, column_names\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/test/notebooks/../../etl/clients.py:125\u001b[0m, in \u001b[0;36mHiveClient.execute_hive_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(query)\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetchall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     column_names \u001b[38;5;241m=\u001b[39m [desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, column_names\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/venv/lib/python3.11/site-packages/pyhive/common.py:142\u001b[0m, in \u001b[0;36mDBAPICursor.fetchall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetchall\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch all (remaining) rows of a query result, returning them as a sequence of sequences\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    (e.g. a list of tuples).\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    An :py:class:`~pyhive.exc.Error` (or subclass) exception is raised if the previous call to\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :py:meth:`execute` did not produce any result set or no call was issued yet.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetchone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/venv/lib/python3.11/site-packages/pyhive/common.py:111\u001b[0m, in \u001b[0;36mDBAPICursor.fetchone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mProgrammingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo query yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Sleep until we're done or we have some data to return\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_while\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_STATE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/venv/lib/python3.11/site-packages/pyhive/common.py:51\u001b[0m, in \u001b[0;36mDBAPICursor._fetch_while\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch_while\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m fn():\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_more\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fn():\n\u001b[1;32m     53\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_interval)\n",
      "File \u001b[0;32m~/LDesktop/Dev-Projects/lib/HadoopDataHub/venv/lib/python3.11/site-packages/pyhive/hive.py:496\u001b[0m, in \u001b[0;36mCursor._fetch_more\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operationHandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have an op handle in _fetch_more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operationHandle\u001b[38;5;241m.\u001b[39mhasResultSet:\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo result set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    497\u001b[0m req \u001b[38;5;241m=\u001b[39m ttypes\u001b[38;5;241m.\u001b[39mTFetchResultsReq(\n\u001b[1;32m    498\u001b[0m     operationHandle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operationHandle,\n\u001b[1;32m    499\u001b[0m     orientation\u001b[38;5;241m=\u001b[39mttypes\u001b[38;5;241m.\u001b[39mTFetchOrientation\u001b[38;5;241m.\u001b[39mFETCH_NEXT,\n\u001b[1;32m    500\u001b[0m     maxRows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marraysize,\n\u001b[1;32m    501\u001b[0m )\n\u001b[1;32m    502\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mFetchResults(req)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: No result set"
     ]
    }
   ],
   "source": [
    "hive.execute_hive_query(hiveql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive.delete_external_table(\"TestCreateDeleteTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark on Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Please be sure you want to execute big queries with spark!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/22 22:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>2d071f8a-cf43-4e1e-91fa-6946b88a1cdf</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13f0e7090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = hive.create_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+---------+-------------+----------+-------+\n",
      "|transaction_date|employee_id|client_id|costcenter_id|paytype_id| amount|\n",
      "+----------------+-----------+---------+-------------+----------+-------+\n",
      "|      2000-11-30|       7119|       83|            1|         1|5579.23|\n",
      "|      2000-11-30|       7119|       83|            1|         2| 976.37|\n",
      "|      2000-11-30|       7119|       83|            1|         3| 836.88|\n",
      "|      2000-11-30|       7119|       83|            1|         4|  697.4|\n",
      "|      2000-11-30|       7119|       83|            1|         5| 557.92|\n",
      "|      2000-11-30|       7119|       83|            1|         6| 418.44|\n",
      "|      2000-11-30|       7119|       83|            1|         7| 278.96|\n",
      "|      2000-11-30|       7119|       83|            1|         8| 139.48|\n",
      "|      2000-11-30|        612|        3|           17|         1|6263.01|\n",
      "|      2000-11-30|        612|        3|           17|         2|1096.03|\n",
      "|      2000-11-30|        612|        3|           17|         3| 939.45|\n",
      "|      2000-11-30|        612|        3|           17|         4| 782.88|\n",
      "|      2000-11-30|        612|        3|           17|         5|  626.3|\n",
      "|      2000-11-30|        612|        3|           17|         6| 469.73|\n",
      "|      2000-11-30|        612|        3|           17|         7| 313.15|\n",
      "|      2000-11-30|        612|        3|           17|         8| 156.58|\n",
      "|      2000-11-30|       4154|       92|           17|         1|5226.72|\n",
      "|      2000-11-30|       4154|       92|           17|         2| 914.68|\n",
      "|      2000-11-30|       4154|       92|           17|         3| 784.01|\n",
      "|      2000-11-30|       4154|       92|           17|         4| 653.34|\n",
      "+----------------+-----------+---------+-------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(f\"SELECT * FROM default.employee_pay_test\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- employee_id: long (nullable = true)\n",
      " |-- client_id: long (nullable = true)\n",
      " |-- costcenter_id: long (nullable = true)\n",
      " |-- paytype_id: long (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===================================================>   (119 + 8) / 127]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------------+\n",
      "|client_id|costcenter_id|        total_amount|\n",
      "+---------+-------------+--------------------+\n",
      "|       92|           10|      3.5432563698E8|\n",
      "|       50|            1| 3.483273433499998E8|\n",
      "|       69|            2|3.3774057639000005E8|\n",
      "|       50|           10|3.6544836635999995E8|\n",
      "|       67|            2| 3.321358519500001E8|\n",
      "|       69|           17| 3.547921280399999E8|\n",
      "|       92|           17| 3.605586988500001E8|\n",
      "|       63|            1|3.5656114536000025E8|\n",
      "|       69|           10|3.5766427473000026E8|\n",
      "|        4|           17| 3.614978070900001E8|\n",
      "|       50|            2|3.6106176014999956E8|\n",
      "|       27|            2|3.5264925234000015E8|\n",
      "|       92|            2|3.5391423122999984E8|\n",
      "|        3|           15| 3.473282307599999E8|\n",
      "|       87|            1| 3.418949929499999E8|\n",
      "|        4|           10| 3.398013108000001E8|\n",
      "|       50|           17|      3.3833523402E8|\n",
      "|       63|           17|3.3902211924000007E8|\n",
      "|       27|           17|      3.5908540101E8|\n",
      "|       67|            1|3.3570917918999994E8|\n",
      "+---------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_agg = df.groupBy(\"client_id\", \"costcenter_id\").agg(f.sum(\"amount\").alias(\"total_amount\"))\n",
    "df_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
